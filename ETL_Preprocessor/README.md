# ğŸ“Š Dynamic DataType Detector using PySpark

## ğŸ“Œ Description  
This project accepts an input file in **CSV**, **JSON**, or **Parquet** format and reads it into a **PySpark DataFrame**. It performs:  
- **Field name validation** using **Python**
- **Dynamic data type detection** using the **Gemini API**  
- Returns a clean, structured DataFrame ready for analysis or loading into any downstream database.

## ğŸ› ï¸ Tech Stack  
- Python  
- Apache Spark (PySpark)
- Regular Expressions (`re`) 
- Gemini API (Detect DataType)  
- File formats: CSV, JSON, Parquet

## â–¶ï¸ How to Run 
âš ï¸ **Important:** Run this on the notebook in Google Colab for the best experience.
1. Clone the repository:
`!git clone https://github.com/MuniDataEngineer/GenAI.git`
2. Run the main.py file:
`%run /content/GenAI/ETL_Preprocessor/main.py`

ğŸŒColab
ğŸ”— https://colab.research.google.com/
