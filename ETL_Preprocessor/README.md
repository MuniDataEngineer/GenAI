# 📊 Dynamic DataType Detector using PySpark

## 📌 Description  
This project accepts an input file in **CSV**, **JSON**, or **Parquet** format and reads it into a **PySpark DataFrame**. It performs:  
- **Field name validation** using **Python**
- **Dynamic data type detection** using the **Gemini API**  
- Returns a clean, structured DataFrame ready for analysis or loading into any downstream database.

## 🛠️ Tech Stack  
- Python  
- Apache Spark (PySpark)
- Regular Expressions (`re`) 
- Gemini API (Detect DataType)  
- File formats: CSV, JSON, Parquet

## ▶️ How to Run 
⚠️ **Important:** Run this on the notebook in Google Colab for the best experience.
1. Clone the repository:
`!git clone https://github.com/MuniDataEngineer/GenAI.git`
2. Run the main.py file:
`%run /content/GenAI/ETL_Preprocessor/main.py`

🌐Colab
🔗 https://colab.research.google.com/
